{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRgYaM56FwiJ",
        "outputId": "906f05d2-ea6c-4fc7-f4e2-626cf07d060f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1l7-pWBrIAbF"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/Face_23C.zip /content/\n",
        "!unzip --qq Face_23C.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_hub\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, models, Model\n",
        "from tensorflow import keras\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "metadata": {
        "id": "cZ7mJ48LbEVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = \"/content/Face_23C\""
      ],
      "metadata": {
        "id": "zM6oF03_cXWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "TRAINING_DATA_DIR = str(data_root)\n",
        "\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR, \n",
        "    subset=\"validation\", \n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE\n",
        ")\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR, \n",
        "    subset=\"training\", \n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "CEtz9vL-8MSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "metadata": {
        "id": "vGWpDYoCci0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmeEQA7UIlGJ"
      },
      "outputs": [],
      "source": [
        "Base_model = InceptionV3(weights = 'imagenet',\n",
        "                          include_top = False,\n",
        "                          input_shape = (224, 224, 3),\n",
        "                          )\n",
        "# Base_model = ResNet50V2(weights = 'imagenet',\n",
        "#                           include_top = False,\n",
        "#                           input_shape = (224, 224, 3),\n",
        "#                           )\n",
        "# Base_model = VGG16(weights = 'imagenet',\n",
        "#                           include_top = False,\n",
        "#                           input_shape = (224, 224, 3),\n",
        "#                           )\n",
        "                   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    Base_model,\n",
        "                                    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(256, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(64, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(32, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "                                    \n",
        "                                    \n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sccsYyoEn301"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A9IBmQ-nrcM"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    loss = 'categorical_crossentropy', \n",
        "    metrics = ['acc'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzj_TfO5bCHV"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
        "\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=300,\n",
        "    verbose=1,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=val_steps_per_epoch).history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_loss, final_accuracy = model.evaluate(valid_generator, steps = val_steps_per_epoch)"
      ],
      "metadata": {
        "id": "wEHbqhfNc1XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final loss: {:.2f}\".format(final_loss))\n",
        "print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))"
      ],
      "metadata": {
        "id": "kOJk37tRc1yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "#plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "plt.legend(['Training loss', 'Validation loss'], loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])\n",
        "plt.legend(['Training accuracy', 'Validation accuracy'], loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SkKxV3gmc492"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XmhT26_M_Gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1cd9d6-9c1c-463c-b9c7-56fa2de6fd89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_models/face_23P/assets\n"
          ]
        }
      ],
      "source": [
        "FACE_SAVED_MODEL = \"saved_models/face_23P\"\n",
        "tf.saved_model.save(model, FACE_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YZ0JUpcW9P3"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_hub\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bMhX1DTNgtK"
      },
      "outputs": [],
      "source": [
        "face_model = hub.load(FACE_SAVED_MODEL)\n",
        "print(face_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl9jPdPAMrqK"
      },
      "outputs": [],
      "source": [
        "!mkdir \"tflite_models\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrObSXDhMsJg"
      },
      "outputs": [],
      "source": [
        "TFLITE_MODEL = \"tflite_models/face.tflite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d22as1pIMu8V"
      },
      "outputs": [],
      "source": [
        "# Get the concrete function from the Keras model.\n",
        "run_model = tf.function(lambda x : face_model(x))\n",
        "\n",
        "# Save the concrete function.\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "VGG-Fine 300Epoch",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}