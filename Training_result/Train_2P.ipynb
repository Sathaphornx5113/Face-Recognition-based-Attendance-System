{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1JoI9mNfaGBgltp0IRdos8VAwFvaHt3Mv","authorship_tag":"ABX9TyMttihmxfOIYWIEZ2GzvN9E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"EPRYKw4rOM2v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631247999059,"user_tz":-420,"elapsed":48878,"user":{"displayName":"SATHAPHORN SIENGPRASEART","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOIrEgxLheNMeGa8E4f_aLox36TimDA2tqs_KD=s64","userId":"02929284411100549340"}},"outputId":"a89c7f23-9eb3-4a11-c6e5-860f15033d6a"},"source":["#Import library for model training \n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from google.colab import drive\n","drive.mount('/gdrive')\n","print(tf.__version__)\n","tf.test.gpu_device_name()\n","\n","#Data images processing\n","img_generator = ImageDataGenerator(rescale = 1 / 255.0,\n","                                   zoom_range = 0.1,\n","                                   width_shift_range = 0.1,\n","                                   height_shift_range = 0.1,\n","                                   shear_range = 0.2,\n","                                   horizontal_flip = True,\n","                                   fill_mode = 'nearest')\n","\n","train = img_generator.flow_from_directory('/gdrive/MyDrive/Colab Notebooks/Dataset', \n","                                          target_size = (224, 224),\n","                                          classes = ['Sathaphorn','Sawanut'],\n","                                          class_mode = 'categorical', \n","                                          batch_size = 32, \n","                                          shuffle = True)\n","based_model = MobileNetV2(weights = 'imagenet',\n","                          include_top = False,\n","                          input_shape = (224, 224, 3))\n","based_model.trainable = False\n","model = Sequential()\n","model.add(based_model)\n","model.add(GlobalAveragePooling2D())\n","model.add(Flatten())\n","model.add(Dense(128))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(2))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","2.6.0\n","Found 500 images belonging to 2 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","9420800/9406464 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 1280)              0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1280)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               163968    \n","_________________________________________________________________\n","activation (Activation)      (None, 128)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 64)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 130       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 2)                 0         \n","=================================================================\n","Total params: 2,430,338\n","Trainable params: 172,354\n","Non-trainable params: 2,257,984\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"RwYPN5fcO5m1","executionInfo":{"status":"ok","timestamp":1631248005606,"user_tz":-420,"elapsed":396,"user":{"displayName":"SATHAPHORN SIENGPRASEART","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOIrEgxLheNMeGa8E4f_aLox36TimDA2tqs_KD=s64","userId":"02929284411100549340"}}},"source":["#Model optimizer\n","opt = Adam(learning_rate = 0.001, decay = 0.001 / 20)\n","model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UxNIwpzape8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631248358526,"user_tz":-420,"elapsed":346649,"user":{"displayName":"SATHAPHORN SIENGPRASEART","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOIrEgxLheNMeGa8E4f_aLox36TimDA2tqs_KD=s64","userId":"02929284411100549340"}},"outputId":"6f6b3127-3656-4f78-b69d-18b5d0fd09a3"},"source":["#Model traning\n","model.fit(train, batch_size = 64, epochs = 10)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","16/16 [==============================] - 182s 12s/step - loss: 0.3162 - accuracy: 0.8860\n","Epoch 2/10\n","16/16 [==============================] - 12s 745ms/step - loss: 0.0404 - accuracy: 0.9920\n","Epoch 3/10\n","16/16 [==============================] - 12s 742ms/step - loss: 0.0069 - accuracy: 1.0000\n","Epoch 4/10\n","16/16 [==============================] - 12s 743ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/10\n","16/16 [==============================] - 12s 752ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 6/10\n","16/16 [==============================] - 12s 766ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 7/10\n","16/16 [==============================] - 12s 744ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 8/10\n","16/16 [==============================] - 12s 747ms/step - loss: 7.9552e-04 - accuracy: 1.0000\n","Epoch 9/10\n","16/16 [==============================] - 12s 741ms/step - loss: 8.7044e-04 - accuracy: 1.0000\n","Epoch 10/10\n","16/16 [==============================] - 12s 742ms/step - loss: 9.4963e-04 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f13ac706b10>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"35ZRe9loas6q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631249339220,"user_tz":-420,"elapsed":25597,"user":{"displayName":"SATHAPHORN SIENGPRASEART","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOIrEgxLheNMeGa8E4f_aLox36TimDA2tqs_KD=s64","userId":"02929284411100549340"}},"outputId":"ba61bbca-c58e-46c7-8d7e-195237c6075e"},"source":["#Save model\n","model.save('/gdrive/MyDrive/Colab Notebooks/face_recognition.model')\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/face_recognition.model/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/face_recognition.model/assets\n","/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]}]}]}